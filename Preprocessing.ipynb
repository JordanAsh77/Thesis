{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b919f185",
   "metadata": {},
   "source": [
    "These notebooks make use of the CrowdTruth framework. I would like to thank the authors for the work that has allowed me to conduct my thesis research.\n",
    "\n",
    "@article{CrowdTruth2,\n",
    "  author    = {Anca Dumitrache and Oana Inel and Lora Aroyo and Benjamin Timmermans and Chris Welty},\n",
    "  title     = {CrowdTruth 2.0: Quality Metrics for Crowdsourcing with Disagreement},\n",
    "  year      = {2018},\n",
    "  url       = {https://arxiv.org/abs/1808.06080},\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c322591",
   "metadata": {},
   "source": [
    "The CrowdTruth package can be installed using: \n",
    "\"pip install crowdtruth\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc5d5c38",
   "metadata": {},
   "source": [
    "# Part 1: Importing the Google Forms data into Pandas DataFrames\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "654ab033",
   "metadata": {},
   "source": [
    "We first import the Annotation Survey results into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f20bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import crowdtruth\n",
    "import csv\n",
    "import os\n",
    "from crowdtruth.configuration import DefaultConfig\n",
    "import dateparser\n",
    "\n",
    "general_df = pd.read_csv(\"data/CrowdTruth_Results.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd6008df",
   "metadata": {},
   "source": [
    "Afterwarsd, we split the dataframes into distinct dataframes. These are then written to distinct csv files which can be used for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c8992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_connection_type  = general_df.groupby('connection_type')\n",
    "grouped_connection_level = general_df.groupby('connection_level')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de1f4ed9",
   "metadata": {},
   "source": [
    "We first group the Annotation results per connection type that the participants self-identified with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb339bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_name, group_df in grouped_connection_type:\n",
    "    group_df.to_csv('data/Niches/' + f'{group_name}.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9abec5a3",
   "metadata": {},
   "source": [
    "Afterwards, we do the same for all of the connection levels that the participants self-identified with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6bf93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_name, group_df in grouped_connection_level:\n",
    "    group_df.to_csv('data/Niches/level_' + f'{group_name}.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e074aa84",
   "metadata": {},
   "source": [
    "# Part 2: Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19d803ec",
   "metadata": {},
   "source": [
    "The pre-processing configuration defines how to interpret the raw csv file with the results. TO do this, we need to define a configuration class. Some default configuration is inherited from DefaultConfig. We also define some additional attributes to the specific photograph annotation task from the annotation survey. Here are the most important ones:\n",
    "\n",
    "- outputColumns: This contains all of the columns with the answers from the participants\n",
    "CustomPLarformColumns: To ensure that the FrameWork functions properly, we need to define a judgment_id, unit_id, worker_id, start_time, and submit_time. This has already been done in the spreadsheet containing the Annotation Survey results.\n",
    "- annotation_seperator: This string seperates between the participant annotations in the outputColumns\n",
    "- annotation_vecotr: This contains a list of all possivle annotation answers\n",
    "- open_ended_task, which is a boolean variable whether the task is open-ended (answer options are known beforehand or not). Participants were given the option to fill in terms that they deemed more relevant in the annotation task, which is why this variable has been set to true\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bea323b",
   "metadata": {},
   "source": [
    "The complete configuration class is declared below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53484b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestConfig(DefaultConfig):\n",
    "    \n",
    "    inputColumns = [\"link\"]\n",
    "    outputColumns = [\"Answer\"]\n",
    "    customPlatformColumns = [\"judgmentId\", \"unitId\", \"workerId\", \"startedAt\", \"submittedAt\"]\n",
    "    open_ended_task = True\n",
    "    annotation_vector = [\"emancipatie\", \"revolutie\", \"vrijheidsstrijd\", \"opstand\",\"onrust\" ,\"gelijkheid\" ,\"protest\" ,\"bevrijding\" ,\"vandalisme\" ,\"rechtvaardigheid\"\n",
    "                         ,\"verwoesting\" ,\"onafhankelijkheid\" ,\"verzet\" ,\"oproer\" ,\"staking\", \"anarchie\", \"opkomen\", \"ongeluk/niet met opzet\", \n",
    "                         \"opstandigheid\", \"omverwerping\", \"uitbraak\", \"dissidentie\", \"ongehoorzaamheid\", \"muiterij\", \"hulp\", \"ongeloof bij de mensen\",\"orde herstellen\",\n",
    "                         \"bemoeienis\", \"onderdrukken\", \"autoriteit\", \"oorlog\", \"(te late) damage control\", \"saamhorigheid\", \"droevigheid\", \"verlies\", \"heel triest\", \"oneerlijkheid\",\n",
    "                         \"destructie\", \"woede \", \"boosheid\", \"vechtlust \", \"wanhoop\", \"eenheid\"]\n",
    "    annotation_separator = \", \"\n",
    "\n",
    "\n",
    "    def processJudgments(self, judgments):\n",
    "        # pre-process output to match the values in annotation_vector\n",
    "        for col in self.outputColumns:\n",
    "            # transform to lowercase\n",
    "            judgments[col] = judgments[col].apply(lambda x: str(x).lower())\n",
    "            # remove square brackets from annotations\n",
    "        return judgments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0da2bde",
   "metadata": {},
   "source": [
    "# Part 3: Defining the functions to generate annotation/unit results\n",
    "We then define one function to preprocess the input csv files that have been filtered on the different niche groups (connection_level/connection_types).\n",
    "The function below generates the following metrics:\n",
    "\n",
    "- The Unit Annotation Score (UAS), which shows the degree to which one annotation is chosen over another annotations. This is shown per annotated photograph\n",
    "- The most frequently selected terms in the complete annotation task. As this was a sparse multiple choice, free input task, this allowed us to show the most commonly selected terms for all of the ten photographs.\n",
    "- The Unit Quality Score (UQS), which showed shows the overall participant agreement in every annotated photograph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d98c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(file):\n",
    "    data, config = crowdtruth.load(\n",
    "    file = file,\n",
    "    config = TestConfig()\n",
    "    )\n",
    "\n",
    "    results = crowdtruth.run(data, config)\n",
    "\n",
    "    uas = results[\"units\"][\"unit_annotation_score\"]\n",
    "    aqs = results[\"annotations\"]\n",
    "    uqs = results[\"units\"][\"uqs\"]\n",
    "\n",
    "\n",
    "    return uas, aqs, uqs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "548fb399",
   "metadata": {},
   "source": [
    "We first do this for every connection level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_directory = 'data/Niches'\n",
    "\n",
    "\n",
    "for root, _, files in os.walk(root_directory):\n",
    "    for file_name in files:\n",
    "        \n",
    "        file_path = os.path.join(root, file_name)\n",
    "\n",
    "        uas, aqs, uqs = calculate_results(file_path)\n",
    "        aqs.to_csv(\"data/results/Grouped_results/AQS/AQS_\" + f\"{file_name}\")\n",
    "        uas.to_csv(\"data/results/Grouped_results/UAS/UAS_\" + f\"{file_name}\")\n",
    "        uqs.to_csv(\"data/results/Grouped_results/UQS/UQS_\" + f\"{file_name}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbf03205",
   "metadata": {},
   "source": [
    "We then do this for every connection type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "195a234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_directory = 'data/results/Grouped_results/Connection_types'\n",
    "\n",
    "# Use os.walk to recursively traverse the directory tree\n",
    "for root, _, files in os.walk(root_directory):\n",
    "    for file_name in files:\n",
    "        # Get the full path of the file\n",
    "        file_path = os.path.join(root, file_name)\n",
    "        print(file_path)\n",
    "\n",
    "        # Call your function with the file path\n",
    "        # uas, aqs, uqs = calculate_results(file_path)\n",
    "        aqs.to_csv(\"data/results/Grouped_results/AQS/AQS_\" + f\"{file_name}\")\n",
    "        uas.to_csv(\"data/results/Grouped_results/UAS/UAS_\" + f\"{file_name}\")\n",
    "        uqs.to_csv(\"data/results/Grouped_results/UQS/UQS_\" + f\"{file_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d20b1fc4",
   "metadata": {},
   "source": [
    "# Part 4: generating Worker results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f6bf56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data, config = crowdtruth.load(\n",
    "    file = 'data/CrowdTruth_Results.csv',\n",
    "    config = TestConfig()\n",
    "    )\n",
    "\n",
    "results = crowdtruth.run(data, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "19dfd5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"workers\"].to_csv('data/results/workers/results.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
